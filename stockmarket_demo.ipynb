{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    ":ext QuasiQuotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import qualified H.Prelude as H\n",
    "H.initialize H.defaultConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " [1] \"ggplot2\"   \"dplyr\"     \"keras\"     \"stats\"     \"graphics\"  \"grDevices\"\n",
       " [7] \"utils\"     \"datasets\"  \"methods\"   \"base\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[rprint|\n",
    "  library(keras)\n",
    "  library(dplyr)\n",
    "  library(ggplot2) |] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "python:         /nix/store/5kfn0xxh3ipjdyjly2d5wrmh4cidsm8k-python3-3.5.3/bin/python\n",
       "libpython:      /nix/store/5kfn0xxh3ipjdyjly2d5wrmh4cidsm8k-python3-3.5.3/lib/libpython3.5m.so\n",
       "pythonhome:     /nix/store/5kfn0xxh3ipjdyjly2d5wrmh4cidsm8k-python3-3.5.3:/nix/store/5kfn0xxh3ipjdyjly2d5wrmh4cidsm8k-python3-3.5.3\n",
       "version:        3.5.3 (default, Jan 17 2017, 07:57:56)  [GCC 5.4.0]\n",
       "numpy:          /nix/store/7xk7ylqagd3w72y1p39rlcsamx3hcxl3-python3.5-numpy-1.12.1/lib/python3.5/site-packages/numpy\n",
       "numpy_version:  1.12.1\n",
       "tensorflow:     /nix/store/qmr3h3f1s1x1dr64sb61igig8469imn6-python3.5-tensorflow-1.1.0/lib/python3.5/site-packages/tensorflow\n",
       "\n",
       "python versions found: \n",
       " /nix/store/5kfn0xxh3ipjdyjly2d5wrmh4cidsm8k-python3-3.5.3/bin/python\n",
       " /usr/bin/python\n",
       " /usr/bin/python3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[rprint| reticulate::py_config() |]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model\n",
       "________________________________________________________________________________\n",
       "Layer (type)                        Output Shape                    Param #     \n",
       "================================================================================\n",
       "lstm_1 (LSTM)                       (None, 4)                       96          \n",
       "________________________________________________________________________________\n",
       "dense_1 (Dense)                     (None, 1)                       5           \n",
       "================================================================================\n",
       "Total params: 101.0\n",
       "Trainable params: 101\n",
       "Non-trainable params: 0.0\n",
       "________________________________________________________________________________\n",
       "\n",
       " \n",
       "NULL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[rprint| \n",
    " \n",
    "  # model\n",
    "  set.seed(22222)\n",
    "  model <- keras_model_sequential() \n",
    "  model %>% \n",
    "    layer_lstm(units = 4, input_shape = c(5, 1)) %>% \n",
    "    layer_dense(units = 1) %>% \n",
    "    compile(\n",
    "      loss = 'mean_squared_error',\n",
    "      optimizer = 'adam'\n",
    "    )\n",
    "  \n",
    "  model %>% summary()  |]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model\n",
       "________________________________________________________________________________\n",
       "Layer (type)                        Output Shape                    Param #     \n",
       "================================================================================\n",
       "lstm_2 (LSTM)                       (None, 4)                       96          \n",
       "________________________________________________________________________________\n",
       "dense_2 (Dense)                     (None, 1)                       5           \n",
       "================================================================================\n",
       "Total params: 101.0\n",
       "Trainable params: 101\n",
       "Non-trainable params: 0.0\n",
       "________________________________________________________________________________\n",
       "\n",
       " \n",
       "Train on 95 samples, validate on 15 samples\n",
       "Epoch 1/5\n",
       "\r",
       " 1/95 [..............................] - ETA: 76s - loss: 0.1097\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "14/95 [===>..........................] - ETA: 5s - loss: 0.2796 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "26/95 [=======>......................] - ETA: 2s - loss: 0.3271\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "35/95 [==========>...................] - ETA: 1s - loss: 0.2993\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "44/95 [============>.................] - ETA: 1s - loss: 0.2605\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "53/95 [===============>..............] - ETA: 0s - loss: 0.2537\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "62/95 [==================>...........] - ETA: 0s - loss: 0.2427\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "74/95 [======================>.......] - ETA: 0s - loss: 0.2089\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "90/95 [===========================>..] - ETA: 0s - loss: 0.1872\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "95/95 [==============================] - 1s - loss: 0.1806 - val_loss: 0.0790\n",
       "Epoch 2/5\n",
       "\r",
       " 1/95 [..............................] - ETA: 0s - loss: 4.9633e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "17/95 [====>.........................] - ETA: 0s - loss: 0.0634    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "33/95 [=========>....................] - ETA: 0s - loss: 0.0526\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "49/95 [==============>...............] - ETA: 0s - loss: 0.0456\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "65/95 [===================>..........] - ETA: 0s - loss: 0.0493\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "81/95 [========================>.....] - ETA: 0s - loss: 0.0474\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "95/95 [==============================] - 0s - loss: 0.0503 - val_loss: 0.0526\n",
       "Epoch 3/5\n",
       "\r",
       " 1/95 [..............................] - ETA: 0s - loss: 0.0633\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "12/95 [==>...........................] - ETA: 0s - loss: 0.0709\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "24/95 [======>.......................] - ETA: 0s - loss: 0.0619\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "35/95 [==========>...................] - ETA: 0s - loss: 0.0518\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "50/95 [==============>...............] - ETA: 0s - loss: 0.0481\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "64/95 [===================>..........] - ETA: 0s - loss: 0.0468\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "75/95 [======================>.......] - ETA: 0s - loss: 0.0485\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "87/95 [==========================>...] - ETA: 0s - loss: 0.0465\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "95/95 [==============================] - 0s - loss: 0.0452 - val_loss: 0.0518\n",
       "Epoch 4/5\n",
       "\r",
       " 1/95 [..............................] - ETA: 0s - loss: 0.0910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "14/95 [===>..........................] - ETA: 0s - loss: 0.0435\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "32/95 [=========>....................] - ETA: 0s - loss: 0.0438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "43/95 [============>.................] - ETA: 0s - loss: 0.0413\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "55/95 [================>.............] - ETA: 0s - loss: 0.0442\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "65/95 [===================>..........] - ETA: 0s - loss: 0.0470\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "76/95 [=======================>......] - ETA: 0s - loss: 0.0459\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "88/95 [==========================>...] - ETA: 0s - loss: 0.0444\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "95/95 [==============================] - 0s - loss: 0.0444 - val_loss: 0.0516\n",
       "Epoch 5/5\n",
       "\r",
       " 1/95 [..............................] - ETA: 0s - loss: 0.0491\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "14/95 [===>..........................] - ETA: 0s - loss: 0.0407\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "28/95 [=======>......................] - ETA: 0s - loss: 0.0446\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "38/95 [===========>..................] - ETA: 0s - loss: 0.0433\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "55/95 [================>.............] - ETA: 0s - loss: 0.0457\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "70/95 [=====================>........] - ETA: 0s - loss: 0.0448\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "88/95 [==========================>...] - ETA: 0s - loss: 0.0446\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "95/95 [==============================] - 0s - loss: 0.0442 - val_loss: 0.0505          [,1]\n",
       " [1,] 114.5609\n",
       " [2,] 114.8354\n",
       " [3,] 120.3540\n",
       " [4,] 118.3493\n",
       " [5,] 122.4943\n",
       " [6,] 115.5477\n",
       " [7,] 119.7571\n",
       " [8,] 122.1208\n",
       " [9,] 124.9095\n",
       "[10,] 126.9840\n",
       "[11,] 125.1937\n",
       "[12,] 126.7588\n",
       "[13,] 126.0969\n",
       "[14,] 129.7269\n",
       "[15,] 129.4937"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[rprint| \n",
    "  lstm_num_timesteps <- 4 # one less now\n",
    "  batch_size <- 1\n",
    "  epochs <- 5\n",
    "  lstm_units <- 4\n",
    "\n",
    "  #\n",
    "  trend_train <- 11:110 + rnorm(100, sd = 2)\n",
    "  trend_test <- 111:130 + rnorm(20, sd =2)\n",
    "  # difference\n",
    "  trend_train_start <- trend_train[1]\n",
    "  trend_test_start <- trend_test[1]\n",
    "  trend_train_diff <- diff(trend_train)\n",
    "  trend_test_diff <- diff(trend_test)\n",
    "  # normalize\n",
    "  minval <- min(trend_train_diff)\n",
    "  maxval <- max(trend_train_diff)\n",
    "  normalize <- function(vec, min, max) {\n",
    "  (vec-min) / (max-min)\n",
    "  }\n",
    "  denormalize <- function(vec,min,max) {\n",
    "  vec * (max - min) + min\n",
    "  }\n",
    "  trend_train_diff <- normalize(trend_train_diff, minval, maxval)\n",
    "  trend_test_diff <- normalize(trend_test_diff, minval, maxval)\n",
    "\n",
    "\n",
    "  # get data into \"timesteps form\"\n",
    "  X_train <- t(sapply(1:(length(trend_train_diff) - lstm_num_timesteps), function(x) trend_train_diff[x:(x + lstm_num_timesteps - 1)]))\n",
    "  y_train <- sapply((lstm_num_timesteps + 1):(length(trend_train_diff)), function(x) trend_train_diff[x])\n",
    "  X_test <- t(sapply(1:(length(trend_test_diff) - lstm_num_timesteps), function(x) trend_test_diff[x:(x + lstm_num_timesteps - 1)]))\n",
    "  y_test <- sapply((lstm_num_timesteps + 1):(length(trend_test_diff)), function(x) trend_test_diff[x])\n",
    "\n",
    "  # Keras LSTMs expect the input array to be shaped as (no. samples, no. time steps, no. features)\n",
    "  dim(X_train) <- c(dim(X_train)[1], dim(X_train)[2], 1)\n",
    "  dim(X_train)\n",
    "  num_samples <- dim(X_train)[1]\n",
    "  num_steps <- dim(X_train)[2]\n",
    "  num_features <- dim(X_train)[3]\n",
    "  c(num_samples, num_steps, num_features)\n",
    "\n",
    "  dim(X_test) <- c(dim(X_test)[1], dim(X_test)[2], 1)\n",
    "\n",
    "  # model\n",
    "  set.seed(22222)\n",
    "  model <- keras_model_sequential() \n",
    "  model %>% \n",
    "    layer_lstm(units = lstm_units, input_shape = c(num_steps, num_features)) %>% \n",
    "    layer_dense(units = 1) %>% \n",
    "    compile(\n",
    "      loss = 'mean_squared_error',\n",
    "      optimizer = 'adam'\n",
    "    )\n",
    "  \n",
    "  model %>% summary()\n",
    "  \n",
    "  model %>% fit( \n",
    "    X_train, y_train, batch_size = batch_size, epochs = epochs, validation_data = list(X_test, y_test)\n",
    "  )\n",
    "  \n",
    "  # model %>% save_model_hdf5(filepath = paste0(model_name, \".h5\"))\n",
    " \n",
    "  pred_train <- model %>% predict(X_train, batch_size = 1)\n",
    "  pred_test <- model %>% predict(X_test, batch_size = 1)\n",
    "\n",
    "  pred_train <- denormalize(pred_train, minval, maxval)\n",
    "  pred_test <- denormalize(pred_test, minval, maxval)\n",
    "\n",
    "  pred_train_undiff <- pred_train + trend_train[(lstm_num_timesteps+1):(length(trend_train)-1)]\n",
    "  pred_test_undiff <- pred_test + trend_test[(lstm_num_timesteps+1):(length(trend_test)-1)]  |]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " #df <- data_frame(time_id = 1:120,\n",
    "  #               train = c(trend_train, rep(NA, length(trend_test))),\n",
    "  #               test = c(rep(NA, length(trend_train)), trend_test),\n",
    "  #               pred_train = c(rep(NA, lstm_num_timesteps+1), pred_train_undiff, rep(NA, length(trend_test))),\n",
    "  #               pred_test = c(rep(NA, length(trend_train)), rep(NA, lstm_num_timesteps+1), pred_test_undiff))\n",
    "  #df <- df %>% gather(key = 'type', value = 'value', train:pred_test)\n",
    "  #ggplot(df, aes(x = time_id, y = value)) + geom_line(aes(color = type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[rprint| 1 + 1 |]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[r| fact <<- function(n) if(n == 0) 1 else n * fact(n - 1) |]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[rprint| fact(10) |]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[rgraph| plot(cars) |]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[rgraph| plot(cars); abline(lm(cars$dist ~ cars$speed), col=\"red\") |]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[r| require(\"ggplot2\") |]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[rgraph|\n",
    "  Xv <- c(rnorm (500, 10,3), rnorm (500, 50, 20), rnorm (500, 70, 20))\n",
    "  Yv <- c(rnorm (500, 10,3), rnorm (500, 70, 5), rnorm (500, 30, 5))\n",
    "  myd <- data.frame(Xv, Yv)\n",
    "\n",
    "  ggplot(myd, aes(x = Xv, y = Yv)) + geom_point() + geom_density2d() + theme_bw() |]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Haskell",
   "language": "haskell",
   "name": "haskell"
  },
  "language_info": {
   "codemirror_mode": "ihaskell",
   "file_extension": ".hs",
   "name": "haskell",
   "version": "7.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
